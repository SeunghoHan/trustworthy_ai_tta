{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "028632dc-7e1a-456e-8ae5-8962534d2bd9",
   "metadata": {},
   "source": [
    "# 2. Bias mitigation algorithms (In-processing)\n",
    "\n",
    "---\n",
    "\n",
    "## 2-1. Adversarial Debiasing\n",
    "\n",
    "### API Reference:\n",
    "- https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.inprocessing.AdversarialDebiasing.html#aif360.algorithms.inprocessing.AdversarialDebiasing\n",
    "\n",
    "### Related paper:\n",
    "- [B. H. Zhang, B. Lemoine, and M. Mitchell, “Mitigating Unwanted Biases with Adversarial Learning,” AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, 2018.](https://dl.acm.org/doi/pdf/10.1145/3278721.3278779)\n",
    "\n",
    "### Description\n",
    "Adversarial debiasing is an in-processing technique that learns a classifier to maximize prediction accuracy and simultaneously reduce an adversary’s ability to determine the protected attribute from the predictions. This approach leads to a fair classifier as the predictions cannot carry any group discrimination information that the adversary can exploit.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f47bd3-b98e-4dc8-a962-5c5fa9132b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "\"\"\"\n",
    "This API is provided in older tensorflow (<2)\n",
    "\"\"\"\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde59292-3571-4e8c-a70a-90e5f3c1fdb6",
   "metadata": {},
   "source": [
    "## Load and preprocess a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e21d399-5413-43f6-a838-9d1b58328ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig = load_preproc_data_adult()\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86270c24-918f-4b94-9ad9-10e6df79130d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34189, 18)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'race']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89852fa6-df64-4a71-bb86-d6125c0230c6",
   "metadata": {},
   "source": [
    "## Measure a fairness using diffrenece in mean outcmoms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef0bc9b-74c4-49d6-aa00-1c68990b16fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.190413\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.204108\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ea1323-514f-48c1-8093-0be67968577c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.190413\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.204108\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7d61b-8e84-4c96-845f-1293f192b8e3",
   "metadata": {},
   "source": [
    "## Train classifier without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91694394-64f6-4094-8141-9b745e5fe6f1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 15:42:51.508462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:51.509266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:51.513706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:51.514476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:51.514872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:51.515620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:51.516372: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-29 15:42:51.690150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:51.690897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:51.691240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:51.691854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:51.692249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:51.692894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:52.200972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:52.201775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:52.202220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:52.202916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:52.203304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:52.203952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22850 MB memory:  -> device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2021-12-29 15:42:52.204330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:42:52.204662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 3084 MB memory:  -> device: 1, name: TITAN RTX, pci bus id: 0000:04:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session()\n",
    "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7f1e967-9763-419e-8ed7-c6b66f883e73",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /archive/library/anaconda3/envs/tta/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691886\n",
      "epoch 0; iter: 200; batch classifier loss: 0.374727\n",
      "epoch 1; iter: 0; batch classifier loss: 0.364818\n",
      "epoch 1; iter: 200; batch classifier loss: 0.381029\n",
      "epoch 2; iter: 0; batch classifier loss: 0.417011\n",
      "epoch 2; iter: 200; batch classifier loss: 0.431710\n",
      "epoch 3; iter: 0; batch classifier loss: 0.457279\n",
      "epoch 3; iter: 200; batch classifier loss: 0.387809\n",
      "epoch 4; iter: 0; batch classifier loss: 0.448797\n",
      "epoch 4; iter: 200; batch classifier loss: 0.366362\n",
      "epoch 5; iter: 0; batch classifier loss: 0.393969\n",
      "epoch 5; iter: 200; batch classifier loss: 0.363461\n",
      "epoch 6; iter: 0; batch classifier loss: 0.427242\n",
      "epoch 6; iter: 200; batch classifier loss: 0.410256\n",
      "epoch 7; iter: 0; batch classifier loss: 0.418294\n",
      "epoch 7; iter: 200; batch classifier loss: 0.463887\n",
      "epoch 8; iter: 0; batch classifier loss: 0.444146\n",
      "epoch 8; iter: 200; batch classifier loss: 0.354700\n",
      "epoch 9; iter: 0; batch classifier loss: 0.376692\n",
      "epoch 9; iter: 200; batch classifier loss: 0.434384\n",
      "epoch 10; iter: 0; batch classifier loss: 0.397439\n",
      "epoch 10; iter: 200; batch classifier loss: 0.499818\n",
      "epoch 11; iter: 0; batch classifier loss: 0.416835\n",
      "epoch 11; iter: 200; batch classifier loss: 0.426751\n",
      "epoch 12; iter: 0; batch classifier loss: 0.396390\n",
      "epoch 12; iter: 200; batch classifier loss: 0.493660\n",
      "epoch 13; iter: 0; batch classifier loss: 0.400709\n",
      "epoch 13; iter: 200; batch classifier loss: 0.392668\n",
      "epoch 14; iter: 0; batch classifier loss: 0.435269\n",
      "epoch 14; iter: 200; batch classifier loss: 0.379782\n",
      "epoch 15; iter: 0; batch classifier loss: 0.427231\n",
      "epoch 15; iter: 200; batch classifier loss: 0.405880\n",
      "epoch 16; iter: 0; batch classifier loss: 0.389556\n",
      "epoch 16; iter: 200; batch classifier loss: 0.456499\n",
      "epoch 17; iter: 0; batch classifier loss: 0.363928\n",
      "epoch 17; iter: 200; batch classifier loss: 0.384022\n",
      "epoch 18; iter: 0; batch classifier loss: 0.387888\n",
      "epoch 18; iter: 200; batch classifier loss: 0.464745\n",
      "epoch 19; iter: 0; batch classifier loss: 0.524258\n",
      "epoch 19; iter: 200; batch classifier loss: 0.480620\n",
      "epoch 20; iter: 0; batch classifier loss: 0.413656\n",
      "epoch 20; iter: 200; batch classifier loss: 0.356617\n",
      "epoch 21; iter: 0; batch classifier loss: 0.441732\n",
      "epoch 21; iter: 200; batch classifier loss: 0.459019\n",
      "epoch 22; iter: 0; batch classifier loss: 0.358307\n",
      "epoch 22; iter: 200; batch classifier loss: 0.378736\n",
      "epoch 23; iter: 0; batch classifier loss: 0.417277\n",
      "epoch 23; iter: 200; batch classifier loss: 0.465557\n",
      "epoch 24; iter: 0; batch classifier loss: 0.386191\n",
      "epoch 24; iter: 200; batch classifier loss: 0.429615\n",
      "epoch 25; iter: 0; batch classifier loss: 0.400756\n",
      "epoch 25; iter: 200; batch classifier loss: 0.465045\n",
      "epoch 26; iter: 0; batch classifier loss: 0.428860\n",
      "epoch 26; iter: 200; batch classifier loss: 0.389959\n",
      "epoch 27; iter: 0; batch classifier loss: 0.373825\n",
      "epoch 27; iter: 200; batch classifier loss: 0.500440\n",
      "epoch 28; iter: 0; batch classifier loss: 0.397937\n",
      "epoch 28; iter: 200; batch classifier loss: 0.486584\n",
      "epoch 29; iter: 0; batch classifier loss: 0.406861\n",
      "epoch 29; iter: 200; batch classifier loss: 0.356839\n",
      "epoch 30; iter: 0; batch classifier loss: 0.376671\n",
      "epoch 30; iter: 200; batch classifier loss: 0.397093\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455510\n",
      "epoch 31; iter: 200; batch classifier loss: 0.430238\n",
      "epoch 32; iter: 0; batch classifier loss: 0.588833\n",
      "epoch 32; iter: 200; batch classifier loss: 0.422037\n",
      "epoch 33; iter: 0; batch classifier loss: 0.407120\n",
      "epoch 33; iter: 200; batch classifier loss: 0.432987\n",
      "epoch 34; iter: 0; batch classifier loss: 0.416125\n",
      "epoch 34; iter: 200; batch classifier loss: 0.325642\n",
      "epoch 35; iter: 0; batch classifier loss: 0.426504\n",
      "epoch 35; iter: 200; batch classifier loss: 0.438988\n",
      "epoch 36; iter: 0; batch classifier loss: 0.440731\n",
      "epoch 36; iter: 200; batch classifier loss: 0.334311\n",
      "epoch 37; iter: 0; batch classifier loss: 0.428791\n",
      "epoch 37; iter: 200; batch classifier loss: 0.405802\n",
      "epoch 38; iter: 0; batch classifier loss: 0.394766\n",
      "epoch 38; iter: 200; batch classifier loss: 0.339030\n",
      "epoch 39; iter: 0; batch classifier loss: 0.388350\n",
      "epoch 39; iter: 200; batch classifier loss: 0.461744\n",
      "epoch 40; iter: 0; batch classifier loss: 0.405140\n",
      "epoch 40; iter: 200; batch classifier loss: 0.359067\n",
      "epoch 41; iter: 0; batch classifier loss: 0.366789\n",
      "epoch 41; iter: 200; batch classifier loss: 0.397659\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411943\n",
      "epoch 42; iter: 200; batch classifier loss: 0.402325\n",
      "epoch 43; iter: 0; batch classifier loss: 0.493977\n",
      "epoch 43; iter: 200; batch classifier loss: 0.381342\n",
      "epoch 44; iter: 0; batch classifier loss: 0.497639\n",
      "epoch 44; iter: 200; batch classifier loss: 0.434541\n",
      "epoch 45; iter: 0; batch classifier loss: 0.361339\n",
      "epoch 45; iter: 200; batch classifier loss: 0.378917\n",
      "epoch 46; iter: 0; batch classifier loss: 0.353937\n",
      "epoch 46; iter: 200; batch classifier loss: 0.360330\n",
      "epoch 47; iter: 0; batch classifier loss: 0.373676\n",
      "epoch 47; iter: 200; batch classifier loss: 0.513006\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382382\n",
      "epoch 48; iter: 200; batch classifier loss: 0.441775\n",
      "epoch 49; iter: 0; batch classifier loss: 0.529208\n",
      "epoch 49; iter: 200; batch classifier loss: 0.391455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7f9854c2fe90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c11058-eb5b-40c9-bb32-2da5ecb1aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_nodebiasing_train = plain_model.predict(dataset_orig_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bde1558-42af-44b9-9450-a18eaaf6e715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.238114\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.231750\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.806593\n",
      "Test set: Balanced classification accuracy = 0.674060\n",
      "Test set: Disparate impact = 0.000000\n",
      "Test set: Equal opportunity difference = -0.489362\n",
      "Test set: Average odds difference = -0.303578\n",
      "Test set: Theil_index = 0.170562\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7510fb0-1b45-4dc5-97f4-192c0d9b5ab9",
   "metadata": {},
   "source": [
    "## Apply in-processing algorithm based on adversarial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4c1e584-04e2-4dcc-9f09-6f6758c11155",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 15:43:32.335818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:43:32.336326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:43:32.336880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:43:32.337358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:43:32.337791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:43:32.338179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:43:32.338701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:43:32.338971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:43:32.339287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:43:32.339521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22850 MB memory:  -> device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2021-12-29 15:43:32.339574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 15:43:32.339865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 3084 MB memory:  -> device: 1, name: TITAN RTX, pci bus id: 0000:04:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e79a247c-dbee-4a65-881d-cf125f1b5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0e1f997-0fdd-4d2d-b25b-866016d5d148",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.683959; batch adversarial loss: 0.926255\n",
      "epoch 0; iter: 200; batch classifier loss: 0.959215; batch adversarial loss: 1.121723\n",
      "epoch 1; iter: 0; batch classifier loss: 1.325486; batch adversarial loss: 1.108459\n",
      "epoch 1; iter: 200; batch classifier loss: 1.144300; batch adversarial loss: 0.890422\n",
      "epoch 2; iter: 0; batch classifier loss: 1.062991; batch adversarial loss: 0.822741\n",
      "epoch 2; iter: 200; batch classifier loss: 0.722432; batch adversarial loss: 0.730646\n",
      "epoch 3; iter: 0; batch classifier loss: 0.661724; batch adversarial loss: 0.668476\n",
      "epoch 3; iter: 200; batch classifier loss: 0.550328; batch adversarial loss: 0.584353\n",
      "epoch 4; iter: 0; batch classifier loss: 0.472047; batch adversarial loss: 0.656036\n",
      "epoch 4; iter: 200; batch classifier loss: 0.426166; batch adversarial loss: 0.597682\n",
      "epoch 5; iter: 0; batch classifier loss: 0.444804; batch adversarial loss: 0.573711\n",
      "epoch 5; iter: 200; batch classifier loss: 0.424269; batch adversarial loss: 0.564708\n",
      "epoch 6; iter: 0; batch classifier loss: 0.401861; batch adversarial loss: 0.626824\n",
      "epoch 6; iter: 200; batch classifier loss: 0.566781; batch adversarial loss: 0.615768\n",
      "epoch 7; iter: 0; batch classifier loss: 0.419883; batch adversarial loss: 0.596081\n",
      "epoch 7; iter: 200; batch classifier loss: 0.482535; batch adversarial loss: 0.634511\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534005; batch adversarial loss: 0.651447\n",
      "epoch 8; iter: 200; batch classifier loss: 0.428558; batch adversarial loss: 0.601037\n",
      "epoch 9; iter: 0; batch classifier loss: 0.395028; batch adversarial loss: 0.632017\n",
      "epoch 9; iter: 200; batch classifier loss: 0.427618; batch adversarial loss: 0.634670\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464361; batch adversarial loss: 0.613090\n",
      "epoch 10; iter: 200; batch classifier loss: 0.398586; batch adversarial loss: 0.630030\n",
      "epoch 11; iter: 0; batch classifier loss: 0.395836; batch adversarial loss: 0.597826\n",
      "epoch 11; iter: 200; batch classifier loss: 0.407422; batch adversarial loss: 0.631163\n",
      "epoch 12; iter: 0; batch classifier loss: 0.443872; batch adversarial loss: 0.568129\n",
      "epoch 12; iter: 200; batch classifier loss: 0.436484; batch adversarial loss: 0.673039\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522765; batch adversarial loss: 0.654098\n",
      "epoch 13; iter: 200; batch classifier loss: 0.421855; batch adversarial loss: 0.570599\n",
      "epoch 14; iter: 0; batch classifier loss: 0.352324; batch adversarial loss: 0.669368\n",
      "epoch 14; iter: 200; batch classifier loss: 0.331661; batch adversarial loss: 0.641849\n",
      "epoch 15; iter: 0; batch classifier loss: 0.386442; batch adversarial loss: 0.595582\n",
      "epoch 15; iter: 200; batch classifier loss: 0.479815; batch adversarial loss: 0.638442\n",
      "epoch 16; iter: 0; batch classifier loss: 0.397264; batch adversarial loss: 0.627976\n",
      "epoch 16; iter: 200; batch classifier loss: 0.443138; batch adversarial loss: 0.603799\n",
      "epoch 17; iter: 0; batch classifier loss: 0.478187; batch adversarial loss: 0.596237\n",
      "epoch 17; iter: 200; batch classifier loss: 0.482018; batch adversarial loss: 0.661845\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458350; batch adversarial loss: 0.602580\n",
      "epoch 18; iter: 200; batch classifier loss: 0.438172; batch adversarial loss: 0.577103\n",
      "epoch 19; iter: 0; batch classifier loss: 0.436746; batch adversarial loss: 0.620092\n",
      "epoch 19; iter: 200; batch classifier loss: 0.436598; batch adversarial loss: 0.613477\n",
      "epoch 20; iter: 0; batch classifier loss: 0.428207; batch adversarial loss: 0.644113\n",
      "epoch 20; iter: 200; batch classifier loss: 0.413763; batch adversarial loss: 0.607923\n",
      "epoch 21; iter: 0; batch classifier loss: 0.476523; batch adversarial loss: 0.579135\n",
      "epoch 21; iter: 200; batch classifier loss: 0.409871; batch adversarial loss: 0.631142\n",
      "epoch 22; iter: 0; batch classifier loss: 0.422342; batch adversarial loss: 0.575656\n",
      "epoch 22; iter: 200; batch classifier loss: 0.395247; batch adversarial loss: 0.561828\n",
      "epoch 23; iter: 0; batch classifier loss: 0.371712; batch adversarial loss: 0.599748\n",
      "epoch 23; iter: 200; batch classifier loss: 0.397221; batch adversarial loss: 0.633516\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489710; batch adversarial loss: 0.584936\n",
      "epoch 24; iter: 200; batch classifier loss: 0.483301; batch adversarial loss: 0.570658\n",
      "epoch 25; iter: 0; batch classifier loss: 0.449637; batch adversarial loss: 0.611453\n",
      "epoch 25; iter: 200; batch classifier loss: 0.441363; batch adversarial loss: 0.613946\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450171; batch adversarial loss: 0.578477\n",
      "epoch 26; iter: 200; batch classifier loss: 0.410101; batch adversarial loss: 0.659276\n",
      "epoch 27; iter: 0; batch classifier loss: 0.391004; batch adversarial loss: 0.547671\n",
      "epoch 27; iter: 200; batch classifier loss: 0.472139; batch adversarial loss: 0.604840\n",
      "epoch 28; iter: 0; batch classifier loss: 0.410093; batch adversarial loss: 0.584583\n",
      "epoch 28; iter: 200; batch classifier loss: 0.484867; batch adversarial loss: 0.623370\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452353; batch adversarial loss: 0.562555\n",
      "epoch 29; iter: 200; batch classifier loss: 0.456426; batch adversarial loss: 0.623426\n",
      "epoch 30; iter: 0; batch classifier loss: 0.570596; batch adversarial loss: 0.585044\n",
      "epoch 30; iter: 200; batch classifier loss: 0.433357; batch adversarial loss: 0.634084\n",
      "epoch 31; iter: 0; batch classifier loss: 0.387745; batch adversarial loss: 0.624276\n",
      "epoch 31; iter: 200; batch classifier loss: 0.492113; batch adversarial loss: 0.668015\n",
      "epoch 32; iter: 0; batch classifier loss: 0.403269; batch adversarial loss: 0.629704\n",
      "epoch 32; iter: 200; batch classifier loss: 0.456425; batch adversarial loss: 0.658344\n",
      "epoch 33; iter: 0; batch classifier loss: 0.478425; batch adversarial loss: 0.565520\n",
      "epoch 33; iter: 200; batch classifier loss: 0.429132; batch adversarial loss: 0.646636\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480310; batch adversarial loss: 0.628983\n",
      "epoch 34; iter: 200; batch classifier loss: 0.470693; batch adversarial loss: 0.529912\n",
      "epoch 35; iter: 0; batch classifier loss: 0.492237; batch adversarial loss: 0.622340\n",
      "epoch 35; iter: 200; batch classifier loss: 0.420549; batch adversarial loss: 0.585294\n",
      "epoch 36; iter: 0; batch classifier loss: 0.356341; batch adversarial loss: 0.619883\n",
      "epoch 36; iter: 200; batch classifier loss: 0.382568; batch adversarial loss: 0.655490\n",
      "epoch 37; iter: 0; batch classifier loss: 0.432427; batch adversarial loss: 0.643965\n",
      "epoch 37; iter: 200; batch classifier loss: 0.423366; batch adversarial loss: 0.581627\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441655; batch adversarial loss: 0.582007\n",
      "epoch 38; iter: 200; batch classifier loss: 0.384525; batch adversarial loss: 0.580813\n",
      "epoch 39; iter: 0; batch classifier loss: 0.501355; batch adversarial loss: 0.579432\n",
      "epoch 39; iter: 200; batch classifier loss: 0.478246; batch adversarial loss: 0.619690\n",
      "epoch 40; iter: 0; batch classifier loss: 0.422606; batch adversarial loss: 0.582274\n",
      "epoch 40; iter: 200; batch classifier loss: 0.437211; batch adversarial loss: 0.601298\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415265; batch adversarial loss: 0.607423\n",
      "epoch 41; iter: 200; batch classifier loss: 0.367213; batch adversarial loss: 0.643773\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449983; batch adversarial loss: 0.564763\n",
      "epoch 42; iter: 200; batch classifier loss: 0.383231; batch adversarial loss: 0.610685\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477632; batch adversarial loss: 0.610834\n",
      "epoch 43; iter: 200; batch classifier loss: 0.414700; batch adversarial loss: 0.642615\n",
      "epoch 44; iter: 0; batch classifier loss: 0.372570; batch adversarial loss: 0.604677\n",
      "epoch 44; iter: 200; batch classifier loss: 0.440797; batch adversarial loss: 0.576214\n",
      "epoch 45; iter: 0; batch classifier loss: 0.390468; batch adversarial loss: 0.661151\n",
      "epoch 45; iter: 200; batch classifier loss: 0.522765; batch adversarial loss: 0.615254\n",
      "epoch 46; iter: 0; batch classifier loss: 0.520592; batch adversarial loss: 0.616975\n",
      "epoch 46; iter: 200; batch classifier loss: 0.397550; batch adversarial loss: 0.609319\n",
      "epoch 47; iter: 0; batch classifier loss: 0.422456; batch adversarial loss: 0.673182\n",
      "epoch 47; iter: 200; batch classifier loss: 0.376210; batch adversarial loss: 0.613273\n",
      "epoch 48; iter: 0; batch classifier loss: 0.493639; batch adversarial loss: 0.585432\n",
      "epoch 48; iter: 200; batch classifier loss: 0.363064; batch adversarial loss: 0.656827\n",
      "epoch 49; iter: 0; batch classifier loss: 0.373014; batch adversarial loss: 0.676294\n",
      "epoch 49; iter: 200; batch classifier loss: 0.387510; batch adversarial loss: 0.582172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7f9854f66150>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(dataset_orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81201b15-d66f-49e4-82a9-e939cd824867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "dataset_debiasing_train = debiased_model.predict(dataset_orig_train)\n",
    "dataset_debiasing_test = debiased_model.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b0300c3-82bc-48e4-aac5-bdf142775aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.238114\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.231750\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.085599\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.086800\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.806593\n",
      "Test set: Balanced classification accuracy = 0.674060\n",
      "Test set: Disparate impact = 0.000000\n",
      "Test set: Equal opportunity difference = -0.489362\n",
      "Test set: Average odds difference = -0.303578\n",
      "Test set: Theil_index = 0.170562\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.793148\n",
      "Test set: Balanced classification accuracy = 0.669039\n",
      "Test set: Disparate impact = 0.571547\n",
      "Test set: Equal opportunity difference = -0.059213\n",
      "Test set: Average odds difference = -0.035725\n",
      "Test set: Theil_index = 0.172505\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(dataset_orig_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf9ef7-3cfe-4269-9158-63aa143f7e99",
   "metadata": {},
   "source": [
    "---\n",
    "## 2-2. Exponentiated Gradient Reduction\n",
    "\n",
    "### API Reference:\n",
    "- https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.inprocessing.ExponentiatedGradientReduction.html#aif360.algorithms.inprocessing.ExponentiatedGradientReduction\n",
    "\n",
    "### Related paper:\n",
    "- [A. Agarwal, A. Beygelzimer, M. Dudik, J. Langford, and H. Wallach, “A Reductions Approach to Fair Classification,” International Conference on Machine Learning, 2018.](hhttps://arxiv.org/abs/1803.02453)\n",
    "\n",
    "### Description\n",
    "Exponentiated gradient reduction for fair classification which is an in-processing technique that reduces fair classification to a sequence of cost-sensitive classification problems, returning a randomized classifier with the lowest empirical error subject to fair classification constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ce00b13-df80-4659-bbb3-8a03519d2bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "from aif360.algorithms.inprocessing.exponentiated_gradient_reduction import ExponentiatedGradientReduction\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa5e6c-5853-4257-a68b-d297d1d0e99f",
   "metadata": {},
   "source": [
    "## Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83c9c841-9c55-46b7-a0b5-5c4c8c7cb90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "dataset_orig = load_preproc_data_adult()\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "np.random.seed(0)\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c1d05a5-2336-40f2-bdf7-04b12ee8b4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34189, 18)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'race']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24528a7e-ca03-4192-8558-cce16b25fb49",
   "metadata": {},
   "source": [
    "## Measure fairness on original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f585c5f9-7463-41da-a6ef-9814af811fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.193075\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.198048\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2c7af2e-9eb7-4200-b441-3451e4dc0af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.193075\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.198048\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "dataset_orig_train.features = min_max_scaler.fit_transform(dataset_orig_train.features)\n",
    "dataset_orig_test.features = min_max_scaler.transform(dataset_orig_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230fa10-ce86-4a1c-9e52-cbfc36cf1828",
   "metadata": {},
   "source": [
    "## Train logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "895837da-6fd7-4090-84b9-d7b0900eab78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8042039172865625\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_orig_train.features\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "\n",
    "lmod = LogisticRegression(solver='lbfgs')\n",
    "lmod.fit(X_train, y_train, sample_weight=dataset_orig_train.instance_weights)\n",
    "\n",
    "X_test = dataset_orig_test.features\n",
    "y_test = dataset_orig_test.labels.ravel()\n",
    "\n",
    "y_pred = lmod.predict(X_test)\n",
    "\n",
    "display(Markdown(\"#### Accuracy\"))\n",
    "lr_acc = accuracy_score(y_test, y_pred)\n",
    "print(lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9dd4138-df46-4952-9e54-fcaa394be017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Average odds difference"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.27273605621431707\n"
     ]
    }
   ],
   "source": [
    "dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "dataset_orig_test_pred.labels = y_pred\n",
    "\n",
    "# positive class index\n",
    "pos_ind = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "dataset_orig_test_pred.scores = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "metric_test = ClassificationMetric(dataset_orig_test, \n",
    "                                    dataset_orig_test_pred,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Average odds difference\"))\n",
    "lr_aod = metric_test.average_odds_difference()\n",
    "print(lr_aod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14a36d-760e-4ee2-9b24-8bcd10bdd55a",
   "metadata": {},
   "source": [
    "## Apply exponentiated gradient reduction\n",
    "\n",
    "Choose a base model for the randomized classifer and train the randomized classifier and observe test accuracy. Other options for `constraints` include \"DemographicParity,\" \"TruePositiveRateDifference\", and \"ErrorRateRatio.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d15439dc-e419-4f6b-a60f-b284f273be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "641856f8-d782-4fd7-a3d2-446c78b9efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) #need for reproducibility\n",
    "exp_grad_red = ExponentiatedGradientReduction(estimator=estimator, \n",
    "                                              constraints=\"EqualizedOdds\",\n",
    "                                              drop_prot_attr=False)\n",
    "exp_grad_red.fit(dataset_orig_train)\n",
    "exp_grad_red_pred = exp_grad_red.predict(dataset_orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ec46629-3950-4c7d-a4ae-0f1cf4cd1bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7865283559680611 (VS. 0.8042039172865625 )\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Average odds difference"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011012958938905922 (VS. -0.27273605621431707 )\n"
     ]
    }
   ],
   "source": [
    "metric_test = ClassificationMetric(dataset_orig_test, \n",
    "                                   exp_grad_red_pred,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "\n",
    "display(Markdown(\"#### Accuracy\"))\n",
    "egr_acc = metric_test.accuracy()\n",
    "print(egr_acc, '(VS.', lr_acc, ')')\n",
    "\n",
    "#Check if accuracy is comparable\n",
    "assert abs(lr_acc-egr_acc)<0.03\n",
    "\n",
    "display(Markdown(\"#### Average odds difference\"))\n",
    "egr_aod = metric_test.average_odds_difference()\n",
    "print(egr_aod, '(VS.', lr_aod, ')')\n",
    "\n",
    "#Check if average odds difference has improved\n",
    "assert abs(egr_aod)<abs(lr_aod)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
