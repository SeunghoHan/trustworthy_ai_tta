{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f50f894d-ee5d-4d48-bc58-18e1a387e44d",
   "metadata": {},
   "source": [
    "# 5. Integrated Gradients\n",
    "\n",
    "Integrated gradients is a method originally proposed in Sundararajan et al., “Axiomatic Attribution for Deep Networks” that aims to attribute an importance value to each input feature of a machine learning model based on the gradients of the model output with respect to the input. In particular, integrated gradients defines an attribution value for each feature by considering the integral of the gradients taken along a straight path from a baseline instance x' to the input instance x.\n",
    "\n",
    "\n",
    "### ALE description:\n",
    "- https://docs.seldon.io/projects/alibi/en/stable/methods/IntegratedGradients.html\n",
    "\n",
    "### API Reference:\n",
    "- https://docs.seldon.io/projects/alibi/en/stable/api/alibi.explainers.html#alibi.explainers.IntegratedGradients\n",
    "\n",
    "### Related paper:\n",
    "- [Sundararajan, Mukund, Ankur Taly, and Qiqi Yan. \"Axiomatic attribution for deep networks.\" International Conference on Machine Learning. PMLR, 2017.](https://arxiv.org/pdf/1703.01365.pdf)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d16ee39-7d54-4216-a0e7-c2ed4157765a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5-1. Integrated gradients for MNIST\n",
    "\n",
    "In this notebook we apply the integrated gradients method to a convolutional network trained on the MNIST dataset. Integrated gradients defines an attribution value for each feature of the input instance (in this case for each pixel in the image) by integrating the model’s gradients with respect to the input along a straight path from a baseline instance x' to the input instance x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86618433-aee1-4d77-ae2d-15406dc76435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/archive/library/anaconda3/envs/tta/lib/python3.7/site-packages/redis/connection.py:72: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.6.2\n",
      "Eager execution enabled:  True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Dense, Dropout\n",
    "from tensorflow.keras.layers import Flatten, Input, Reshape, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from alibi.explainers import IntegratedGradients\n",
    "import matplotlib.pyplot as plt\n",
    "print('TF version: ', tf.__version__)\n",
    "print('Eager execution enabled: ', tf.executing_eagerly()) # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4f2b3-3c48-4125-b885-055c5a36fb51",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Loading and preparing the MNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08dfad0-7cd4-43a5-aec3-7e0226c7c54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 10) (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "X_train, y_train = train\n",
    "X_test, y_test = test\n",
    "test_labels = y_test.copy()\n",
    "train_labels = y_train.copy()\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float64') / 255\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float64') / 255\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1205777-2922-40e7-949b-32bd8bd7414f",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "Train a convolutional neural network on the MNIST dataset. The model includes 2 convolutional layers and it reaches a test accuracy of 0.98. If `save_model = True`, a local folder `./model_mnist` will be created and the trained model will be saved in that folder. If the model was previously saved, it can be loaded by setting `oad_mnist_model = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb9bfec-b977-4a46-ac3b-1983ff516e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_mnist_model = False\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "038b72cf-434e-435b-8679-9286542910be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.5039 - accuracy: 0.8390 - val_loss: 0.1314 - val_accuracy: 0.9624\n",
      "Epoch 2/6\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1807 - accuracy: 0.9445 - val_loss: 0.0791 - val_accuracy: 0.9747\n",
      "Epoch 3/6\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1315 - accuracy: 0.9596 - val_loss: 0.0612 - val_accuracy: 0.9813\n",
      "Epoch 4/6\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1076 - accuracy: 0.9662 - val_loss: 0.0502 - val_accuracy: 0.9838\n",
      "Epoch 5/6\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0928 - accuracy: 0.9711 - val_loss: 0.0423 - val_accuracy: 0.9871\n",
      "Epoch 6/6\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0797 - accuracy: 0.9753 - val_loss: 0.0373 - val_accuracy: 0.9878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efc70587c10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "inputs = Input(shape=(X_train.shape[1:]), dtype=tf.float64)\n",
    "x = Conv2D(64, 2, padding='same', activation='relu')(inputs)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(.3)(x)\n",
    "\n",
    "x = Conv2D(32, 2, padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(.3)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(.5)(x)\n",
    "logits = Dense(10, name='logits')(x)\n",
    "outputs = Activation('softmax', name='softmax')(logits)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=6,\n",
    "          batch_size=256,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test)\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2482672f-1f17-4253-b1cc-af918453a055",
   "metadata": {},
   "source": [
    "### Calculate integrated gradients\n",
    "\n",
    "The IntegratedGradients class implements the integrated gradients attribution method. A description of the method can be found here.\n",
    "\n",
    "In the following example, the baselines (i.e. the starting points of the path integral) are black images (all pixel values are set to zero). This means that black areas of the image will always have zero attribution. The path integral is defined as a straight line from the baseline to the input image. The path is approximated by choosing 50 discrete steps according to the Gauss-Legendre method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c70b6b7-2cd9-4475-b9ee-a1398619b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IntegratedGradients instance\n",
    "n_steps = 50\n",
    "method = \"gausslegendre\"  # Method for the integral approximation. \n",
    "                          # Methods available: “riemann_left”, “riemann_right”, \n",
    "                          # “riemann_middle”, “riemann_trapezoid”, “gausslegendre”.\n",
    "        \n",
    "ig  = IntegratedGradients(model,\n",
    "                          n_steps=n_steps,\n",
    "                          method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44e515b9-6aec-4a45-8cff-72c57a0c8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate attributions for the first 10 images in the test set\n",
    "nb_samples = 10\n",
    "X_test_sample = X_test[:nb_samples]\n",
    "predictions = model(X_test_sample)\n",
    "# print(predictions.argmax(axis=1))\n",
    "predictions = model(X_test_sample).numpy().argmax(axis=1)\n",
    "explanation = ig.explain(X_test_sample,\n",
    "                         baselines=None,\n",
    "                         target=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "babf0eb1-67ed-4eb1-bc1c-83e002e8faa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'IntegratedGradients',\n",
       " 'type': ['whitebox'],\n",
       " 'explanations': ['local'],\n",
       " 'params': {'method': 'gausslegendre',\n",
       "  'n_steps': 50,\n",
       "  'internal_batch_size': 100,\n",
       "  'layer': 0},\n",
       " 'version': '0.6.2'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metadata from the explanation object\n",
    "explanation.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0fd0953-d57a-4e4f-ab9f-2c605ad0dc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['attributions', 'X', 'forward_kwargs', 'baselines', 'predictions', 'deltas', 'target'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data fields from the explanation object\n",
    "explanation.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd379ffc-49af-4c95-abca-83d77fdb9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get attributions values from the explanation object\n",
    "attrs = explanation.attributions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04eafdf-3fd5-4cf8-9f36-197b00ca5f21",
   "metadata": {},
   "source": [
    "### Visualize attributions\n",
    "Sample images from the test dataset and their attributions.\n",
    "\n",
    "- The first column shows the original image.\n",
    "- The second column shows the values of the attributions.\n",
    "- The third column shows the positive valued attributions.\n",
    "- The fourth column shows the negative valued attributions.\n",
    "\n",
    "The attributions are calculated using the black image as a baseline for all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b2f6a1-f8a7-4f39-ac2f-b7ad5e59a200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(10, 7))\n",
    "image_ids = [0, 1, 9]\n",
    "cmap_bound = np.abs(attrs[[0, 1, 9]]).max()\n",
    "\n",
    "for row, image_id in enumerate(image_ids):\n",
    "    # original images\n",
    "    ax[row, 0].imshow(X_test[image_id].squeeze(), cmap='gray')\n",
    "    ax[row, 0].set_title(f'Prediction: {predictions[image_id]}')\n",
    "\n",
    "    # attributions\n",
    "    attr = attrs[image_id]\n",
    "    im = ax[row, 1].imshow(attr.squeeze(), vmin=-cmap_bound, vmax=cmap_bound, cmap='PiYG')\n",
    "\n",
    "    # positive attributions\n",
    "    attr_pos = attr.clip(0, 1)\n",
    "    im_pos = ax[row, 2].imshow(attr_pos.squeeze(), vmin=-cmap_bound, vmax=cmap_bound, cmap='PiYG')\n",
    "\n",
    "    # negative attributions\n",
    "    attr_neg = attr.clip(-1, 0)\n",
    "    im_neg = ax[row, 3].imshow(attr_neg.squeeze(), vmin=-cmap_bound, vmax=cmap_bound, cmap='PiYG')\n",
    "\n",
    "ax[0, 1].set_title('Attributions');\n",
    "ax[0, 2].set_title('Positive attributions');\n",
    "ax[0, 3].set_title('Negative attributions');\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.colorbar(im, cax=fig.add_axes([0.95, 0.25, 0.03, 0.5]));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9067562a-b2b6-42af-b4c0-436e57fede25",
   "metadata": {},
   "source": [
    "## 5-2. Integrated gradients for transformers models\n",
    "\n",
    "In this example, we apply the integrated gradients method to two different sentiment analysis models. The first one is a pretrained sentiment analysis model from the transformers library. The second model is a combination of a pretrained BERT model and a simple feed forward network. The feed forward network is trained on the IMDB dataset using the BERT output embeddings as features.\n",
    "\n",
    "In text classification models, integrated gradients define an attribution value for each word in the input sentence. The attributions are calculated considering the integral of the model gradients with respect to the word embedding layer along a straight path from a baseline instance x' to the input instance x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "232c9cb7-bab4-465f-ac2a-d6a51eae86ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import BertTokenizerFast, TFBertModel, BertConfig\n",
    "from alibi.explainers import IntegratedGradients\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5564a4-20c8-4553-a44a-2fde43c869c0",
   "metadata": {},
   "source": [
    "Here we define some functions needed to process the data. For consistency with other text examples in alibi, we will use the IMDB dataset provided by keras. Since the dataset consists of reviews that are already tokenized, we need to decode each sentence and re-convert them into tokens using the BERT tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f19e89b-a721-49a2-9e4c-4c1be291be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentence(x, reverse_index):\n",
    "    \"\"\"Decodes the tokenized sentences from keras IMDB dataset into plain text.\n",
    "    \"\"\"\n",
    "    # the `-3` offset is due to the special tokens used by keras\n",
    "    # see https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset\n",
    "    return \" \".join([reverse_index.get(i - 3, 'UNK') for i in x])\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \"\"\"Preprocess the text.\n",
    "    \"\"\"\n",
    "    REPLACE_NO_SPACE = re.compile(\"[.;:,!\\'?\\\"()\\[\\]]\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "\n",
    "    return reviews\n",
    "\n",
    "def process_sentences(sentence,\n",
    "                      tokenizer,\n",
    "                      max_len):\n",
    "    \"\"\"Tokenize the text sentences.\n",
    "    \"\"\"\n",
    "    z = tokenizer(sentence,\n",
    "                  add_special_tokens = False,\n",
    "                  padding = 'max_length',\n",
    "                  max_length = max_len,\n",
    "                  truncation = True,\n",
    "                  return_token_type_ids=True,\n",
    "                  return_attention_mask = True,\n",
    "                  return_tensors = 'np')\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a271601-1d3a-4cf3-9a17-17b4bcf67ef7",
   "metadata": {},
   "source": [
    "### Automodel\n",
    "\n",
    "In this section, we will use the tensorflow auto model for sequence classification provided by the transformers library.\n",
    "\n",
    "The model is pre-trained on the Stanford Sentiment Treebank (SST) dataset. The Stanford Sentiment Treebank is the first corpus with fully labeled parse trees that allows for a complete analysis of the compositional effects of sentiment in language.\n",
    "\n",
    "Each phrase is labelled as either negative, somewhat negative, neutral, somewhat positive or positive. The corpus with all 5 labels is referred to as SST-5 or SST fine-grained. Binary classification experiments on full sentences (negative or somewhat negative vs somewhat positive or positive with neutral sentences discarded) refer to the dataset as SST-2 or SST binary. In this example, we will use a text classifier pre-trained on the SST-2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81ae3599-e991-4ba6-8249-4da79c5c4d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 12:16:27.328502: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_25']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "auto_model_bert = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879e0090-7bce-43b7-ba54-2685fc15a204",
   "metadata": {},
   "source": [
    "The automodel output is a custom object containing the output logits. We use a wrapper to transform the output into a tensor and apply a softmax function to the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe26afd7-073f-40c1-a98d-337d39543368",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoModelWrapper(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, model_bert, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model_bert = model_bert\n",
    "\n",
    "    def call(self, inputs, attention_mask=None):\n",
    "        out = self.model_bert(inputs,\n",
    "                              attention_mask=attention_mask)\n",
    "        return tf.nn.softmax(out.logits)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1efe320b-30b7-4afe-8d4a-93f4fcb0d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = AutoModelWrapper(auto_model_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf55755-b169-4163-82f1-3afbe8232d7d",
   "metadata": {},
   "source": [
    "### Calculate integrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e85e756-b971-40e0-a86e-c63d92d651a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214dd7f6-7ebb-4df8-aef2-1cd89da04295",
   "metadata": {},
   "source": [
    "Here we consider some simple sentences such as “I love you, I like you”, “I love you, I like you, but I also kind of dislike you” ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56c6fd4e-3bad-4e3a-89fc-523b59ab0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z_test_sample = ['I love you, I like you',\n",
    "                'I love you, I like you, but I also kind of dislike you']\n",
    "z_test_sample = preprocess_reviews(z_test_sample)\n",
    "z_test_sample = process_sentences(z_test_sample,\n",
    "                                   tokenizer,\n",
    "                                   max_len)\n",
    "x_test_sample = z_test_sample['input_ids']\n",
    "\n",
    "# the values of the kwargs have to be `tf.Tensor`.\n",
    "# see transformers issue #14404: https://github.com/huggingface/transformers/issues/14404\n",
    "kwargs = {k: tf.constant(v) for k,v in z_test_sample.items() if k == 'attention_mask'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f78c5bf-d8d2-4ddb-912b-8602c97046e6",
   "metadata": {},
   "source": [
    "The auto model consists of a main BERT layer (layer 0) followed by two dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a1cc433-66b5-4021-890a-8b291e86e3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertMainLayer at 0x7efd0632e490>,\n",
       " <keras.layers.core.Dense at 0x7efc48054b50>,\n",
       " <keras.layers.core.Dense at 0x7efc48054f50>,\n",
       " <keras.layers.core.Dropout at 0x7efc3c5d4250>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac6872-08d8-4fb5-947a-a21fb130df17",
   "metadata": {},
   "source": [
    "We extract the first transformer’s block in the main BERT layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a479d70-89d5-4fd3-949a-64a11e6da836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Extracting the first transformer block\n",
    "bl = auto_model.layers[0].layers[0].transformer.layer[1]\n",
    "\n",
    "n_steps = 5\n",
    "method = \"gausslegendre\"\n",
    "internal_batch_size = 5\n",
    "ig  = IntegratedGradients(auto_model,\n",
    "                          layer=bl,\n",
    "                          n_steps=n_steps,\n",
    "                          method=method,\n",
    "                          internal_batch_size=internal_batch_size)\n",
    "\n",
    "predictions = auto_model(x_test_sample, **kwargs).numpy().argmax(axis=1)\n",
    "explanation = ig.explain(x_test_sample,\n",
    "                         forward_kwargs=kwargs,\n",
    "                         baselines=None,\n",
    "                         target=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b655ff6d-4aa5-4093-9c81-c9f7a72ab81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (2, 100, 768)\n"
     ]
    }
   ],
   "source": [
    "# Get attributions values from the explanation object\n",
    "attrs = explanation.attributions[0]\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f1f2e61-de65-4583-b98a-bcf9b1bb221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (2, 100)\n"
     ]
    }
   ],
   "source": [
    "attrs = attrs.sum(axis=2)\n",
    "print('Attributions shape:', attrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f31df80-e894-4e8e-a583-03c88a2e5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "x_i = x_test_sample[i]\n",
    "attrs_i = attrs[i]\n",
    "pred = predictions[i]\n",
    "pred_dict = {1: 'Positive review', 0: 'Negative review'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "973c19bb-81cf-43a2-a753-39e52ff1163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "def  hlstr(string, color='white'):\n",
    "    \"\"\"\n",
    "    Return HTML markup highlighting text with the desired color.\n",
    "    \"\"\"\n",
    "    return f\"<mark style=background-color:{color}>{string} </mark>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf314ec5-a410-4a1b-aa26-e9779496df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize(attrs, cmap='PiYG'):\n",
    "    \"\"\"\n",
    "    Compute hex colors based on the attributions for a single instance.\n",
    "    Uses a diverging colorscale by default and normalizes and scales\n",
    "    the colormap so that colors are consistent with the attributions.\n",
    "    \"\"\"\n",
    "    cmap_bound = np.abs(attrs).max()\n",
    "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
    "    cmap = mpl.cm.get_cmap(cmap)\n",
    "\n",
    "    # now compute hex values of colors\n",
    "    colors = list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7de60db1-a0d3-4d69-98f0-db892b02df3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label =  1: Positive review\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<mark style=background-color:#f9f1f5>i </mark><mark style=background-color:#276419>love </mark><mark style=background-color:#cfebaa>you </mark><mark style=background-color:#edf6e1>i </mark><mark style=background-color:#7dba40>like </mark><mark style=background-color:#e2f3ca>you </mark><mark style=background-color:#f8cee6>but </mark><mark style=background-color:#faebf3>i </mark><mark style=background-color:#b9e187>also </mark><mark style=background-color:#f3bdde>kind </mark><mark style=background-color:#faeaf2>of </mark><mark style=background-color:#e58dbe>dislike </mark><mark style=background-color:#bde38d>you </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark><mark style=background-color:#f7f7f6>[PAD] </mark>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tokenizer.decode(x_i).split()\n",
    "colors = colorize(attrs_i)\n",
    "print('Predicted label =  {}: {}'.format(pred, pred_dict[pred]))\n",
    "\n",
    "HTML(\"\".join(list(map(hlstr, words, colors))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086002d2-2a5c-42ab-8fe4-93527ab3ae8f",
   "metadata": {},
   "source": [
    "### Sentiment analysis on IMDB with fine-tuned model head.\n",
    "\n",
    "We consider a text classifier fine-tuned on the IMDB dataset. We train a feed forward network which uses the concatenated output embeddings of a pretrained BERT model as input features. The BERT model and the trained ffn are combined to obtain an end-to-end text classifier.\n",
    "\n",
    "It must be noted that training an end-to-end text classifier (i. e. combining the BERT model and the feed forward network before training) instead of training the feed forward network separately is likely to lead to better model performance. However, the latter approach is considerably faster and lighter. We use this approach here since performance optimization is beyond the scope of this notebook and the purpose of this example is to illustrate the integrated gradients method applied to a custom classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1bd04c3-3800-49de-a31e-d8dec5286362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(X_train, model, batch_size=50):\n",
    "    args = X_train['input_ids']\n",
    "    # the values of the kwargs have to be `tf.Tensor`.\n",
    "    # see transformers issue #14404: https://github.com/huggingface/transformers/issues/14404\n",
    "    kwargs = {k: tf.constant(v) for k, v in  X_train.items() if k != 'input_ids'}\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((args, kwargs)).batch(batch_size)\n",
    "\n",
    "    embbedings = []\n",
    "    for X_batch in tqdm(dataset):\n",
    "        args_b, kwargs_b = X_batch\n",
    "        batch_embeddings = model(args_b, **kwargs_b)\n",
    "        embbedings.append(batch_embeddings.last_hidden_state.numpy())\n",
    "\n",
    "    return np.concatenate(embbedings, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11273405-7fae-4c7b-81a4-388bdf977600",
   "metadata": {},
   "source": [
    "### Load and process data\n",
    "Loading the IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6966868-f644-4f1e-9f4c-5260de35d9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "test_labels = y_test.copy()\n",
    "train_labels = y_train.copy()\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "index = imdb.get_word_index()\n",
    "reverse_index = {value: key for (key, value) in index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e99482-9f25-42d0-8d57-098de414ddbf",
   "metadata": {},
   "source": [
    "### Extract embeddings for training\n",
    "In order to speed up the training, the BERT embeddings are pre-extracted and used as features by the feed forward network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51e58c64-a064-4933-86fe-4b8534873d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "modelBert = TFBertModel.from_pretrained(\"bert-base-uncased\", config=config)\n",
    "\n",
    "modelBert.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6003a1f2-1459-4e4d-9537-5b37ac04cf94",
   "metadata": {},
   "source": [
    "Decoding each sentence in the keras IMDB tokenized dataset to obtain the corresponding plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "812d41dc-f571-41f3-b5a1-88f1449f3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = [], []\n",
    "for i in range(len(x_train)):\n",
    "    tr_sentence = decode_sentence(x_train[i], reverse_index)\n",
    "    X_train.append(tr_sentence)\n",
    "    te_sentence = decode_sentence(x_test[i], reverse_index)\n",
    "    X_test.append(te_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d82ed2-fbfd-41b7-8b76-4ee948e6e280",
   "metadata": {},
   "source": [
    "Re-tokenizing the plain text using the BERT tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3318bb02-e058-4175-acf0-a319dfa83381",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_reviews(X_train)\n",
    "X_train = process_sentences(X_train, tokenizer, max_len)\n",
    "X_test = preprocess_reviews(X_test)\n",
    "X_test = process_sentences(X_test, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b382267-9dd9-4e18-b6ac-184868e1f2e8",
   "metadata": {},
   "source": [
    "Extracting the BERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e44171a-4d89-49c8-ba8d-d72fe87d9d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:53<00:00,  4.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:54<00:00,  4.56it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embbedings = get_embeddings(X_train,\n",
    "                                  modelBert,\n",
    "                                  batch_size=100)\n",
    "test_embbedings = get_embeddings(X_test,\n",
    "                                 modelBert,\n",
    "                                 batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaee26a-6e9f-4ebb-ab2f-436c062a04e1",
   "metadata": {},
   "source": [
    "### Train model\n",
    "Here we train the model head using the BERT output embeddings as features. The output embeddings are tensors of dimension 100 X 768, where each 768-dimensional vector represents a word in a sentence of 100 words. The embedding vectors are concatenated along the first dimension in order to represents a full review. The model head consists of one dense layer 128 hidden units followed by a 2 units layer with softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba63d10a-47e7-4d3d-80e1-7739b3a833e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.1\n",
    "hidden_dims = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c118c9a-c9fd-4e9f-a31e-56a9230cae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOut(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dropout=0.2,\n",
    "                 hidden_dims=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.hidden_dims = hidden_dims\n",
    "\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.dense_1 =  tf.keras.layers.Dense(hidden_dims,\n",
    "                                              activation='relu')\n",
    "        self.dropoutl = tf.keras.layers.Dropout(dropout)\n",
    "        self.dense_2 = tf.keras.layers.Dense(2,\n",
    "                                             activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.flat(inputs)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dropoutl(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"dropout\": self.dropout,\n",
    "                \"hidden_dims\": self.hidden_dims}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e5f5def-9020-4fb1-ae4c-6ff6c544d300",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = ModelOut(dropout=dropout, hidden_dims=hidden_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ecb3a-ab69-4e23-9dd6-3c4ac2e240ae",
   "metadata": {},
   "source": [
    "Training the model. If the model has been already trained, it can be loaded from the checkpoint directory setting load_model=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8b9a858-464e-403d-965b-787050d755a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "batch_size = 128\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5e494f5-479c-40c7-96f4-58009a07b6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 12:22:00.121282: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 7680000000 exceeds 10% of free system memory.\n",
      "2021-12-29 12:22:03.170570: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 7680000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.5787 - accuracy: 0.7144 - val_loss: 0.4419 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00001: saving model to ./model_transformers/training/cp-0001.ckpt\n",
      "Epoch 2/3\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.4484 - accuracy: 0.7914 - val_loss: 0.4358 - val_accuracy: 0.8100\n",
      "\n",
      "Epoch 00002: saving model to ./model_transformers/training/cp-0002.ckpt\n",
      "Epoch 3/3\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.4078 - accuracy: 0.8142 - val_loss: 0.4623 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00003: saving model to ./model_transformers/training/cp-0003.ckpt\n"
     ]
    }
   ],
   "source": [
    "filepath = './model_transformers/'  # change to desired save directory\n",
    "\n",
    "model_out.compile(optimizer=Adam(1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "if not load_model:\n",
    "\n",
    "    checkpoint_path = os.path.join(filepath, \"training/cp-{epoch:04d}.ckpt\")\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights every epoch\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        verbose=1,\n",
    "        save_weights_only=True,\n",
    "        save_freq='epoch')\n",
    "\n",
    "    # using the entire testing dataset might result in memory issues when running on GPU\n",
    "    model_out.fit(train_embbedings, y_train,\n",
    "                  validation_data=(test_embbedings[:100], y_test[:100]),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  callbacks=[cp_callback],\n",
    "                  verbose=1)\n",
    "else:\n",
    "    epoch = 3\n",
    "    load_path = os.path.join(filepath, f\"training/cp-{epoch:04d}.ckpt\")\n",
    "    model_out.load_weights(load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce525585-5342-4a98-8e98-282e4382e38c",
   "metadata": {},
   "source": [
    "### Combine BERT and feed forward network\n",
    "\n",
    "Here we combine the BERT model with the model head to obtain an end-to-end text classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed5ba4db-067b-4a91-bb6f-c7fbb9a1f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, model_bert, model_out):\n",
    "        super().__init__()\n",
    "        self.model_bert = model_bert\n",
    "        self.model_out = model_out\n",
    "\n",
    "    def call(self, inputs, attention_mask=None):\n",
    "        out = self.model_bert(inputs, attention_mask=attention_mask)\n",
    "        out = self.model_out(out.last_hidden_state)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5aec5195-9aa8-4e2c-a925-c0a3f26c691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier = TextClassifier(modelBert, model_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e795d8ba-af8f-47f1-bd41-8cbca33b2f79",
   "metadata": {},
   "source": [
    "### Calculate integrated gradients\n",
    "\n",
    "We pick the first 10 sentences from the test set as examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06145e76-a557-4b18-b237-afebb52693ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_test_sample = [decode_sentence(x_test[i], reverse_index) for i in range(10)]\n",
    "z_test_sample = preprocess_reviews(z_test_sample)\n",
    "z_test_sample = process_sentences(z_test_sample, tokenizer, max_len)\n",
    "\n",
    "x_test_sample = z_test_sample['input_ids']\n",
    "# the values of the kwargs have to be `tf.Tensor`.\n",
    "# see transformers issue #14404: https://github.com/huggingface/transformers/issues/14404\n",
    "kwargs = {k:tf.constant(v) for k,v in z_test_sample.items() if k == 'attention_mask'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd167e5-3189-46dc-b2f6-2d94d25fcdec",
   "metadata": {},
   "source": [
    "We calculate the attributions with respect to the first embedding layer of the BERT encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d951844-5aab-45b1-a471-3a6f70c9d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl = text_classifier.layers[0].bert.encoder.layer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e8de357-e097-412f-a3b3-3aa32a4e53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 5\n",
    "method = \"gausslegendre\"\n",
    "internal_batch_size = 5\n",
    "ig  = IntegratedGradients(text_classifier,\n",
    "                          layer=bl,\n",
    "                          n_steps=n_steps,\n",
    "                          method=method,\n",
    "                          internal_batch_size=internal_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7eb3189-286b-4d32-8e36-26f52f194a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_classifier(x_test_sample, **kwargs).numpy().argmax(axis=1)\n",
    "explanation = ig.explain(x_test_sample,\n",
    "                         forward_kwargs=kwargs,\n",
    "                         baselines=None,\n",
    "                         target=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1cca546-b946-4dad-89eb-70fd46c176a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions shape: (10, 100, 768)\n",
      "Attributions shape: (10, 100)\n"
     ]
    }
   ],
   "source": [
    "# Get attributions values from the explanation object\n",
    "attrs = explanation.attributions[0]\n",
    "print('Attributions shape:', attrs.shape)\n",
    "\n",
    "attrs = attrs.sum(axis=2)\n",
    "print('Attributions shape:', attrs.shape)\n",
    "\n",
    "i = 1\n",
    "x_i = x_test_sample[i]\n",
    "attrs_i = attrs[i]\n",
    "pred = predictions[i]\n",
    "pred_dict = {1: 'Positive review', 0: 'Negative review'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f91804d-e715-4f0a-a18e-155a22d3959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "def  hlstr(string, color='white'):\n",
    "    \"\"\"\n",
    "    Return HTML markup highlighting text with the desired color.\n",
    "    \"\"\"\n",
    "    return f\"<mark style=background-color:{color}>{string} </mark>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95f0c66e-70a3-4237-a4f2-95e95b28451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize(attrs, cmap='PiYG'):\n",
    "    \"\"\"\n",
    "    Compute hex colors based on the attributions for a single instance.\n",
    "    Uses a diverging colorscale by default and normalizes and scales\n",
    "    the colormap so that colors are consistent with the attributions.\n",
    "    \"\"\"\n",
    "    import matplotlib as mpl\n",
    "    cmap_bound = np.abs(attrs).max()\n",
    "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
    "    cmap = mpl.cm.get_cmap(cmap)\n",
    "\n",
    "    # now compute hex values of colors\n",
    "    colors = list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3d7efdc-2211-49be-8132-22dbce5d73ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label =  1: Positive review\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<mark style=background-color:#faebf3>a </mark><mark style=background-color:#81bd44>powerful </mark><mark style=background-color:#cbe9a4>study </mark><mark style=background-color:#dff2c4>of </mark><mark style=background-color:#fbe9f2>loneliness </mark><mark style=background-color:#f1f6ea>sexual </mark><mark style=background-color:#f5f7f2>unk </mark><mark style=background-color:#eef6e2>and </mark><mark style=background-color:#f3f6ed>desperation </mark><mark style=background-color:#d0ecad>be </mark><mark style=background-color:#cbe9a4>patient </mark><mark style=background-color:#f4f7f0>unk </mark><mark style=background-color:#f2f6ec>up </mark><mark style=background-color:#e9f5d8>the </mark><mark style=background-color:#e7f5d2>atmosphere </mark><mark style=background-color:#7fbc41>and </mark><mark style=background-color:#e9f5d6>pay </mark><mark style=background-color:#e7f5d2>attention </mark><mark style=background-color:#b2dd7f>to </mark><mark style=background-color:#d9f0bc>the </mark><mark style=background-color:#f3f7ef>wonderfully </mark><mark style=background-color:#f8f2f5>written </mark><mark style=background-color:#acd977>script </mark><mark style=background-color:#ebf6db>br </mark><mark style=background-color:#c4e699>br </mark><mark style=background-color:#d965a4>i </mark><mark style=background-color:#fbe8f2>praise </mark><mark style=background-color:#ea9fca>robert </mark><mark style=background-color:#cbe9a4>altman </mark><mark style=background-color:#f9eef4>this </mark><mark style=background-color:#e7f5d3>is </mark><mark style=background-color:#c6e79c>one </mark><mark style=background-color:#bee490>of </mark><mark style=background-color:#fce5f1>his </mark><mark style=background-color:#f1f6e8>many </mark><mark style=background-color:#d8efb9>films </mark><mark style=background-color:#f2f6ec>that </mark><mark style=background-color:#eff6e4>deals </mark><mark style=background-color:#faeaf2>with </mark><mark style=background-color:#f2f6ec>unconventional </mark><mark style=background-color:#fbe9f2>fascinating </mark><mark style=background-color:#f1f6ea>subject </mark><mark style=background-color:#f8f4f6>matter </mark><mark style=background-color:#ebf6dc>this </mark><mark style=background-color:#c4e699>film </mark><mark style=background-color:#aeda7a>is </mark><mark style=background-color:#eff6e5>disturbing </mark><mark style=background-color:#98cc5f>but </mark><mark style=background-color:#e7f5d2>its </mark><mark style=background-color:#dff2c4>sincere </mark><mark style=background-color:#f1f6ea>and </mark><mark style=background-color:#eaf5d9>its </mark><mark style=background-color:#edf6df>sure </mark><mark style=background-color:#f9eff4>to </mark><mark style=background-color:#f9eff4>unk </mark><mark style=background-color:#f3f6ed>a </mark><mark style=background-color:#ddf1c1>strong </mark><mark style=background-color:#fde2f0>emotional </mark><mark style=background-color:#f8f2f5>response </mark><mark style=background-color:#f3f6ed>from </mark><mark style=background-color:#d4edb3>the </mark><mark style=background-color:#d9f0bc>viewer </mark><mark style=background-color:#cbe9a4>if </mark><mark style=background-color:#e9f5d8>you </mark><mark style=background-color:#f2f6ec>want </mark><mark style=background-color:#fcdded>to </mark><mark style=background-color:#77b53c>see </mark><mark style=background-color:#f1f6ea>an </mark><mark style=background-color:#dbf0bf>unusual </mark><mark style=background-color:#ddf1c1>film </mark><mark style=background-color:#f2f6ec>some </mark><mark style=background-color:#f9f0f5>might </mark><mark style=background-color:#f7cce5>even </mark><mark style=background-color:#fbe7f2>say </mark><mark style=background-color:#faecf3>bizarre </mark><mark style=background-color:#e9f5d6>this </mark><mark style=background-color:#e795c3>is </mark><mark style=background-color:#fad6ea>worth </mark><mark style=background-color:#f1f6e8>the </mark><mark style=background-color:#fce3f0>time </mark><mark style=background-color:#bde38d>br </mark><mark style=background-color:#e1f3c7>br </mark><mark style=background-color:#f3f7ef>unfortunately </mark><mark style=background-color:#f9eef4>its </mark><mark style=background-color:#fad6ea>very </mark><mark style=background-color:#f0b2d7>difficult </mark><mark style=background-color:#e9f5d8>to </mark><mark style=background-color:#8e0152>find </mark><mark style=background-color:#eff6e4>in </mark><mark style=background-color:#f7cbe4>video </mark><mark style=background-color:#f9f0f5>stores </mark><mark style=background-color:#fde1ef>you </mark><mark style=background-color:#f9d3e8>may </mark><mark style=background-color:#fad6ea>have </mark><mark style=background-color:#faebf3>to </mark>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tokenizer.decode(x_i).split()\n",
    "colors = colorize(attrs_i)\n",
    "print('Predicted label =  {}: {}'.format(pred, pred_dict[pred]))\n",
    "\n",
    "HTML(\"\".join(list(map(hlstr, words, colors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afbe269-70d7-466f-87b1-23a69d5bd128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
