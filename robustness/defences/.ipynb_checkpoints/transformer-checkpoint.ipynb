{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4f93fd5-e8f8-4e5d-8847-5ab6fb9a5701",
   "metadata": {},
   "source": [
    "# Transformer \n",
    "---\n",
    "\n",
    "## 1. STRIP for defending backdoor poisoning attacks\n",
    "\n",
    "### API Reference:\n",
    "- https://adversarial-robustness-toolbox.readthedocs.io/en/latest/modules/defences/transformer_poisoning.html#strip\n",
    "\n",
    "### Related paper:\n",
    "- https://arxiv.org/abs/1902.06531\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1c538-04ec-496d-ae7e-2d9a5d0302ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution() # To use the ART\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import tensorflow.keras as tk\n",
    "import tensorflow.keras.layers as tkl\n",
    "from tensorflow.keras import datasets, layers, models, Sequential\n",
    "import tensorflow.keras.backend as k\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
    "from art.attacks.poisoning.perturbations import add_pattern_bd, add_single_bd, insert_image\n",
    "from art.utils import load_mnist, preprocess\n",
    "from art.defences.detector.poison import ActivationDefence\n",
    "from art.defences.transformer.poisoning import STRIP\n",
    "\n",
    "mnist_model_path = '/archive/workspace/TTA/demo/models/baisc_cnn_mnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc01f5-4a9e-4449-834a-ff0109e78800",
   "metadata": {},
   "source": [
    "### Load dataset (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24d2eb-36dc-4aff-ba05-a1f1c9e9fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_raw, y_raw), (x_raw_test, y_raw_test), min_, max_ = load_mnist(raw=True)\n",
    "\n",
    "# Random Selection:\n",
    "n_train = np.shape(x_raw)[0]\n",
    "num_selection = 7500\n",
    "random_selection_indices = np.random.choice(n_train, num_selection)\n",
    "x_raw = x_raw[random_selection_indices]\n",
    "y_raw = y_raw[random_selection_indices]\n",
    "\n",
    "BACKDOOR_TYPE = \"pattern\" # one of ['pattern', 'pixel', 'image']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e026b852-46a2-4be9-9cb5-be9899cfa4cf",
   "metadata": {},
   "source": [
    "### Generate poisoning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd50105-9000-4a1b-b409-d82b4d4b8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = np.max(x_raw)\n",
    "def add_modification(x):\n",
    "        if BACKDOOR_TYPE == 'pattern':\n",
    "            return add_pattern_bd(x, pixel_value=max_val)\n",
    "        elif BACKDOOR_TYPE == 'pixel':\n",
    "            return add_single_bd(x, pixel_value=max_val) \n",
    "        elif BACKDOOR_TYPE == 'image':\n",
    "            return insert_image(x, backdoor_path='../utils/data/backdoors/alert.png', size=(10,10))\n",
    "        else:\n",
    "            raise(\"Unknown backdoor type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366efc9-b996-458c-b0cc-c69c575630a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_dataset(x_clean, y_clean, percent_poison, poison_func):\n",
    "    x_poison = np.copy(x_clean)\n",
    "    y_poison = np.copy(y_clean)\n",
    "    is_poison = np.zeros(np.shape(y_poison))\n",
    "    \n",
    "    sources = np.arange(10)\n",
    "    targets = np.array([1] * 10)\n",
    "    for i, (src, tgt) in enumerate(zip(sources, targets)):\n",
    "        n_points_in_tgt = np.size(np.where(y_clean == tgt))\n",
    "        num_poison = round((percent_poison * n_points_in_tgt) / (1 - percent_poison))\n",
    "        src_imgs = x_clean[y_clean == src]\n",
    "\n",
    "        n_points_in_src = np.shape(src_imgs)[0]\n",
    "        indices_to_be_poisoned = np.random.choice(n_points_in_src, num_poison)\n",
    "\n",
    "        imgs_to_be_poisoned = np.copy(src_imgs[indices_to_be_poisoned])\n",
    "        backdoor_attack = PoisoningAttackBackdoor(poison_func)\n",
    "        imgs_to_be_poisoned, poison_labels = backdoor_attack.poison(imgs_to_be_poisoned, y=np.ones(num_poison) * tgt)\n",
    "        x_poison = np.append(x_poison, imgs_to_be_poisoned, axis=0)\n",
    "        y_poison = np.append(y_poison, poison_labels, axis=0)\n",
    "        is_poison = np.append(is_poison, np.ones(num_poison))\n",
    "\n",
    "    is_poison = is_poison != 0\n",
    "\n",
    "    return is_poison, x_poison, y_poison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe64e3-ad6e-482f-9a82-145f833ac803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poison training data\n",
    "percent_poison = .33\n",
    "(is_poison_train, x_poisoned_raw, y_poisoned_raw) = poison_dataset(x_raw, y_raw, percent_poison, add_modification)\n",
    "x_train, y_train = preprocess(x_poisoned_raw, y_poisoned_raw)\n",
    "# Add channel axis:\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "\n",
    "# Poison test data\n",
    "(is_poison_test, x_poisoned_raw_test, y_poisoned_raw_test) = poison_dataset(x_raw_test, y_raw_test, percent_poison, add_modification)\n",
    "x_test, y_test = preprocess(x_poisoned_raw_test, y_poisoned_raw_test)\n",
    "# Add channel axis:\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "# Shuffle training data\n",
    "n_train = np.shape(y_train)[0]\n",
    "shuffled_indices = np.arange(n_train)\n",
    "np.random.shuffle(shuffled_indices)\n",
    "x_train = x_train[shuffled_indices]\n",
    "y_train = y_train[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabfaa82-ed65-4501-87d1-56006d1438b8",
   "metadata": {},
   "source": [
    "### Train model with poisoned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357ad23-97e2-4e0b-be78-182e8d26638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 14:33:00.913168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:00.913747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:00.917405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:00.917955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:00.918485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:00.919024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Create Keras convolutional neural network - basic architecture from Keras examples\n",
    "# Source here: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b2a3a-9c01-49c8-883a-223d7176be9f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11640 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 14:33:11.348251: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-21 14:33:11.512507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:11.513227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:11.513853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:11.514476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:11.515063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:11.515644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:12.017209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:12.017968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:12.018590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:12.019235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:12.019719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:12.020336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22850 MB memory:  -> device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2021-12-21 14:33:12.020616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-21 14:33:12.021133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 16692 MB memory:  -> device: 1, name: TITAN RTX, pci bus id: 0000:04:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 14:33:12.662133: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      "11640/11640 [==============================] - 1s 76us/sample - loss: 0.1420 - accuracy: 0.9580\n",
      "11640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      "11008/11640 [===========================>..] - ETA: 0s - loss: 0.1423 - accuracy: 0.957711640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      "10240/11640 [=========================>....] - ETA: 0s - loss: 0.1415 - accuracy: 0.957111640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 9600/11640 [=======================>......] - ETA: 0s - loss: 0.1433 - accuracy: 0.956511640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 8960/11640 [======================>.......] - ETA: 0s - loss: 0.1456 - accuracy: 0.955811640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 8192/11640 [====================>.........] - ETA: 0s - loss: 0.1474 - accuracy: 0.955611640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 7424/11640 [==================>...........] - ETA: 0s - loss: 0.1480 - accuracy: 0.955411640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 6784/11640 [================>.............] - ETA: 0s - loss: 0.1491 - accuracy: 0.955611640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 6144/11640 [==============>...............] - ETA: 0s - loss: 0.1508 - accuracy: 0.954611640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 5504/11640 [=============>................] - ETA: 0s - loss: 0.1549 - accuracy: 0.953111640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 4864/11640 [===========>..................] - ETA: 0s - loss: 0.1548 - accuracy: 0.952311640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 4224/11640 [=========>....................] - ETA: 0s - loss: 0.1608 - accuracy: 0.949611640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 3584/11640 [========>.....................] - ETA: 0s - loss: 0.1630 - accuracy: 0.948911640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 2944/11640 [======>.......................] - ETA: 0s - loss: 0.1700 - accuracy: 0.946011640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 2304/11640 [====>.........................] - ETA: 0s - loss: 0.1745 - accuracy: 0.943611640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      " 1536/11640 [==>...........................] - ETA: 0s - loss: 0.1575 - accuracy: 0.944711640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      "  896/11640 [=>............................] - ETA: 0s - loss: 0.1753 - accuracy: 0.937511640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "Epoch 3/3\n",
      "  128/11640 [..............................] - ETA: 0s - loss: 0.1670 - accuracy: 0.945311640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 72us/sample - loss: 0.2137 - accuracy: 0.9370\n",
      "11640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.937011640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "10752/11640 [==========================>...] - ETA: 0s - loss: 0.2179 - accuracy: 0.935811640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 9856/11640 [========================>.....] - ETA: 0s - loss: 0.2205 - accuracy: 0.935011640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 8704/11640 [=====================>........] - ETA: 0s - loss: 0.2211 - accuracy: 0.934411640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 7680/11640 [==================>...........] - ETA: 0s - loss: 0.2288 - accuracy: 0.932211640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 7040/11640 [=================>............] - ETA: 0s - loss: 0.2343 - accuracy: 0.930411640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 6400/11640 [===============>..............] - ETA: 0s - loss: 0.2427 - accuracy: 0.928411640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 5760/11640 [=============>................] - ETA: 0s - loss: 0.2478 - accuracy: 0.926711640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 5120/11640 [============>.................] - ETA: 0s - loss: 0.2515 - accuracy: 0.925411640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 4480/11640 [==========>...................] - ETA: 0s - loss: 0.2511 - accuracy: 0.924311640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 3840/11640 [========>.....................] - ETA: 0s - loss: 0.2547 - accuracy: 0.923211640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 3200/11640 [=======>......................] - ETA: 0s - loss: 0.2646 - accuracy: 0.918411640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 2560/11640 [=====>........................] - ETA: 0s - loss: 0.2682 - accuracy: 0.917211640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 1920/11640 [===>..........................] - ETA: 0s - loss: 0.2747 - accuracy: 0.914111640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      " 1152/11640 [=>............................] - ETA: 0s - loss: 0.2745 - accuracy: 0.910611640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "Epoch 2/3\n",
      "  128/11640 [..............................] - ETA: 0s - loss: 0.3598 - accuracy: 0.906211640/11640 [==============================] - 2s 168us/sample - loss: 0.7672 - accuracy: 0.7515\n",
      "11640/11640 [==============================] - ETA: 0s - loss: 0.7672 - accuracy: 0.751511520/11640 [============================>.] - ETA: 0s - loss: 0.7721 - accuracy: 0.749710880/11640 [===========================>..] - ETA: 0s - loss: 0.8001 - accuracy: 0.740810240/11640 [=========================>....] - ETA: 0s - loss: 0.8267 - accuracy: 0.7311 9600/11640 [=======================>......] - ETA: 0s - loss: 0.8554 - accuracy: 0.7211 8960/11640 [======================>.......] - ETA: 0s - loss: 0.8917 - accuracy: 0.7090 7936/11640 [===================>..........] - ETA: 0s - loss: 0.9463 - accuracy: 0.6891 6784/11640 [================>.............] - ETA: 1s - loss: 1.0381 - accuracy: 0.6573 6144/11640 [==============>...............] - ETA: 1s - loss: 1.0996 - accuracy: 0.6357 5504/11640 [=============>................] - ETA: 1s - loss: 1.1701 - accuracy: 0.6116 4864/11640 [===========>..................] - ETA: 1s - loss: 1.2533 - accuracy: 0.5824 4096/11640 [=========>....................] - ETA: 2s - loss: 1.3587 - accuracy: 0.5459 3072/11640 [======>.......................] - ETA: 3s - loss: 1.5246 - accuracy: 0.4906 2176/11640 [====>.........................] - ETA: 5s - loss: 1.7240 - accuracy: 0.4265  1152/11640 [=>............................] - ETA: 10s - loss: 1.9622 - accuracy: 0.3802   128/11640 [..............................] - ETA: 1:40 - loss: 2.3595 - accuracy: 0.0391"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(model=model, clip_values=(min_, max_))\n",
    "classifier.fit(x_train, y_train, nb_epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d772e4-e08a-448e-93a2-d06e091aeeda",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "#### Evaluate the model with original samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d154a-32af-49f3-81da-30a651aa07de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clean test set accuracy: 96.85%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOJklEQVR4nO3df6zddX3H8dfLcmmh6EYFyhWaAQbckASUm0qQORhZA0TXMiej20x1LEWFRRMXhwwHLG42bKJuKvMqDZ1hiBsQMGFO1kGYMaFcWG1LC5SxMtqVFsKyFiPtbfveH/cLXuF+P+f2nO/5cXk/H8nJOef7Pt/zfd9DX3zP+X7O93wcEQLwxvemfjcAoDcIO5AEYQeSIOxAEoQdSOKQXm7sUM+OOZrby00Cqbysn2hv7PFUtY7CbvsCSV+RNEvStyJiRenxczRX7/H5nWwSQMFDsbq21vbbeNuzJH1N0oWSTpW01Pap7T4fgO7q5DP7QklPRcTTEbFX0nckLW6mLQBN6yTsx0l6dtL9rdWyn2N7ue0x22Pj2tPB5gB0outH4yNiNCJGImJkSLO7vTkANToJ+zZJCybdP75aBmAAdRL2hyWdbPtE24dKulTSPc20BaBpbQ+9RcQ+21dK+hdNDL2tjIjHGusMQKM6GmePiHsl3dtQLwC6iK/LAkkQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BET6dsRu/N+sVfKNaf+OpJxfrj532rWL9m55nF+vrfO6W2tn/jk8V10Sz27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsb3AHTjy+WF9/7jeK9fEoP//nj3mkWD/94rNrawsYZ++pjsJue4uk3ZL2S9oXESNNNAWgeU3s2c+LiBcaeB4AXcRndiCJTsMekn5g+xHby6d6gO3ltsdsj41rT4ebA9CuTt/GnxMR22wfI+k+249HxIOTHxARo5JGJektntficA+Abulozx4R26rrnZLukrSwiaYANK/tsNuea/vNr9yWtEjShqYaA9CsTt7Gz5d0l+1XnucfIuL7jXSFg3LIgvqx9BNHn+phJxhkbYc9Ip6WdHqDvQDoIobegCQIO5AEYQeSIOxAEoQdSIJTXGeA//6z+tNEJenMCzbW1m4Y/vem2zkoR5z9fG3t2c+V/66j1u0r1g+7e01bPWXFnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcfQZYd/nfFuvjsb9HnRy8B06/tb7Y4pzJu34yXKyv3L2kWD/k38o/c50Ne3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9gEw9EB5PHnIs3rUycH7j70HivUt40fX1i6e+2Jx3UuO2Fmuf3u0WH//cWcW69mwZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhn74GfLllYrH90+B+L9Vbnq3fzfPbTVn+sWD969exiffb/1ff22XPL+5r1H/qbYr2VrZ+t/13647/wo46eeyZquWe3vdL2TtsbJi2bZ/s+25ur6yO72yaATk3nbfwtki54zbKrJK2OiJMlra7uAxhgLcMeEQ9Keu33GhdLWlXdXiVpSbNtAWhau5/Z50fE9ur2c5Lm1z3Q9nJJyyVpjg5vc3MAOtXx0fiICElRqI9GxEhEjAypfDAHQPe0G/Ydtoclqboun54EoO/aDfs9kpZVt5dJuruZdgB0S8vP7LZvk3SupKNsb5V0raQVkr5r+zJJz0i6pJtNDrpZ73xHsf75G8vnXY8curfVFg6yo59p9dvr19z/wWL9Vz7zeLG+f9eug+7pFe/YfEqxvuY35xTrC2e/XKz/88dvqK0tmvOZ4ron/GX5N+djz55ifRC1DHtELK0pnd9wLwC6iK/LAkkQdiAJwg4kQdiBJAg7kASnuDbgwKHll7H10Fpn/uCZ156n9DO7f+ew4rqnbF1TrHdzMuj9G58s1j9xS/n02rHLv1ysD8+q/9sfvay87gfvXFasx483FeuDiD07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPsMcPWOkWJ91x++tba2f+vmptvpmRPueKFY/9ySs4r1Fcc+3GQ7Mx57diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2Hhhy+z8FLUnr3l074U5l5o6lF9nF8iFvOlCsd/K6/8/15fqxS9p+6r5hzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDO3oAnPn54sT4e3fz19TeuLb9Vf56+JP3T0eXfvB+P+nH2Vv9N3nZtsazyCP9garlnt73S9k7bGyYtu872Nttrq8tF3W0TQKem8zb+FklTTTnypYg4o7rc22xbAJrWMuwR8aCkF3vQC4Au6uQA3ZW211Vv84+se5Dt5bbHbI+Na08HmwPQiXbDfpOkt0s6Q9J2SV+se2BEjEbESESMDGl2m5sD0Km2wh4ROyJif0QckPRNSQubbQtA09oKu+3hSXcvlrSh7rEABkPLcXbbt0k6V9JRtrdKulbSubbPkBSStki6vHstDr5rfvV7/W5hYB2y4Pja2u4z31Zc9+8++vWm23nVmj1zinXv3de1bfdLy7BHxNIpFt/chV4AdBFflwWSIOxAEoQdSIKwA0kQdiAJTnFFV228/tja2mOLvtrVbd/x0lG1tZv++EPFdedsKp8+OxOxZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnR0eGHhgu1r8wfEePOnm9W7adXVub87033jh6K+zZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtkbMMvlCXyHXD918HTs+t2z2l73+j8v/xDweYe93PZzS63/tvLUyJ29Lq3Er2/r6vPPNOzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtkbsOL23y7WL7nsyx09/4N/9bVivTyWXTYeba86zedvv7dWTlv9sWL9ZD3atW3PRC337LYX2L7f9kbbj9n+ZLV8nu37bG+uro/sfrsA2jWdt/H7JH06Ik6VdJakK2yfKukqSasj4mRJq6v7AAZUy7BHxPaIeLS6vVvSJknHSVosaVX1sFWSlnSpRwANOKjP7LZPkPQuSQ9Jmh8R26vSc5Lm16yzXNJySZqjw9tuFEBnpn003vYRku6Q9KmI2DW5FhEhacpDPRExGhEjETEypNkdNQugfdMKu+0hTQT91oi4s1q8w/ZwVR+WtLM7LQJoQsu38bYt6WZJmyLixkmleyQtk7Siur67Kx3OACfd/kKxvub35xTrC2d3dprpIFuzp/5vH33u14rr/u8n6qd7lqRf/q+nivXuDfrNTNP5zP5eSR+WtN722mrZ1ZoI+XdtXybpGUmXdKVDAI1oGfaI+KEk15TPb7YdAN3C12WBJAg7kARhB5Ig7EAShB1IwhNffuuNt3hevMf5DuD/dPHCYv3ZD5R/ivrJC79RrHfzNNJWWv2U9Olf/6Pa2oK/+FHT7aT3UKzWrnhxytEz9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kAQ/Jd0Dh929plg/pcUvAbxv6RXF+tBHdtTWvv/O24vrLtpwabF+4JZjivWoOx+ycsLa52trnG/eW+zZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJzmcH3kA4nx0AYQeyIOxAEoQdSIKwA0kQdiAJwg4k0TLsthfYvt/2RtuP2f5ktfw629tsr60uF3W/XQDtms6PV+yT9OmIeNT2myU9Yvu+qvaliPjr7rUHoCnTmZ99u6Tt1e3dtjdJOq7bjQFo1kF9Zrd9gqR3SXqoWnSl7XW2V9o+smad5bbHbI+Na09n3QJo27TDbvsISXdI+lRE7JJ0k6S3SzpDE3v+L061XkSMRsRIRIwMaXbnHQNoy7TCbntIE0G/NSLulKSI2BER+yPigKRvSirPXgigr6ZzNN6Sbpa0KSJunLR8eNLDLpa0ofn2ADRlOkfj3yvpw5LW215bLbta0lLbZ0gKSVskXd6F/gA0ZDpH438oaarzY+9tvh0A3cI36IAkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0n0dMpm289LembSoqMkvdCzBg7OoPY2qH1J9NauJnv7pYg4eqpCT8P+uo3bYxEx0rcGCga1t0HtS6K3dvWqN97GA0kQdiCJfod9tM/bLxnU3ga1L4ne2tWT3vr6mR1A7/R7zw6gRwg7kERfwm77AttP2H7K9lX96KGO7S2211fTUI/1uZeVtnfa3jBp2Tzb99neXF1POcden3obiGm8C9OM9/W16/f05z3/zG57lqQnJf2GpK2SHpa0NCI29rSRGra3SBqJiL5/AcP2+yS9JOnvI+K0atkNkl6MiBXV/yiPjIg/GZDerpP0Ur+n8a5mKxqePM24pCWSPqI+vnaFvi5RD163fuzZF0p6KiKejoi9kr4jaXEf+hh4EfGgpBdfs3ixpFXV7VWa+MfSczW9DYSI2B4Rj1a3d0t6ZZrxvr52hb56oh9hP07Ss5Pub9Vgzfcekn5g+xHby/vdzBTmR8T26vZzkub3s5kptJzGu5deM834wLx27Ux/3ikO0L3eORHxbkkXSrqiers6kGLiM9ggjZ1OaxrvXplimvFX9fO1a3f68071I+zbJC2YdP/4atlAiIht1fVOSXdp8Kai3vHKDLrV9c4+9/OqQZrGe6ppxjUAr10/pz/vR9gflnSy7RNtHyrpUkn39KGP17E9tzpwIttzJS3S4E1FfY+kZdXtZZLu7mMvP2dQpvGum2ZcfX7t+j79eUT0/CLpIk0ckf9PSX/ajx5q+jpJ0o+ry2P97k3SbZp4WzeuiWMbl0l6q6TVkjZL+ldJ8waot29LWi9pnSaCNdyn3s7RxFv0dZLWVpeL+v3aFfrqyevG12WBJDhAByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D+QqTBlC3HSJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "clean_x_test = x_test[is_poison_test == 0]\n",
    "clean_y_test = y_test[is_poison_test == 0]\n",
    "\n",
    "clean_preds = np.argmax(classifier.predict(clean_x_test), axis=1)\n",
    "clean_correct = np.sum(clean_preds == np.argmax(clean_y_test, axis=1))\n",
    "clean_total = clean_y_test.shape[0]\n",
    "\n",
    "clean_acc = clean_correct / clean_total\n",
    "print(\"\\nClean test set accuracy: %.2f%%\" % (clean_acc * 100))\n",
    "\n",
    "# Display image, label, and prediction for a clean sample to show how the poisoned model classifies a clean sample\n",
    "\n",
    "c = 0 # class to display\n",
    "i = 0 # image of the class to display\n",
    "\n",
    "c_idx = np.where(np.argmax(clean_y_test,1) == c)[0][i] # index of the image in clean arrays\n",
    "\n",
    "plt.imshow(clean_x_test[c_idx].squeeze())\n",
    "plt.show()\n",
    "clean_label = c\n",
    "print(\"Prediction: \" + str(clean_preds[c_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7d991a-a8f1-4eba-87b3-b45efd59becb",
   "metadata": {},
   "source": [
    "#### Evaluate the model with poisoning samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e6210-6b89-4e62-85d2-59549e798b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1\n",
      "\n",
      " Effectiveness of poison: 100.00%\n"
     ]
    }
   ],
   "source": [
    "poison_x_test = x_test[is_poison_test]\n",
    "poison_y_test = y_test[is_poison_test]\n",
    "\n",
    "poison_preds = np.argmax(classifier.predict(poison_x_test), axis=1)\n",
    "poison_correct = np.sum(poison_preds == np.argmax(poison_y_test, axis=1))\n",
    "poison_total = poison_y_test.shape[0]\n",
    "\n",
    "# Display image, label, and prediction for a poisoned image to see the backdoor working\n",
    "\n",
    "c = 1 # class to display\n",
    "i = 0 # image of the class to display\n",
    "\n",
    "c_idx = np.where(np.argmax(poison_y_test,1) == c)[0][i] # index of the image in poison arrays\n",
    "\n",
    "plt.imshow(poison_x_test[c_idx].squeeze())\n",
    "plt.show()\n",
    "poison_label = c\n",
    "print(\"Prediction: \" + str(poison_preds[c_idx]))\n",
    "\n",
    "poison_acc = poison_correct / poison_total\n",
    "print(\"\\n Effectiveness of poison: %.2f%%\" % (poison_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d84569-84f7-4038-a847-f46c3b932064",
   "metadata": {},
   "source": [
    "#### Evaluate accuracy on entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa32949-4611-4adc-9ed2-80f85b68a45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Overall test set accuracy (i.e. effectiveness of poison): 97.98%\n"
     ]
    }
   ],
   "source": [
    "total_correct = clean_correct + poison_correct\n",
    "total = clean_total + poison_total\n",
    "\n",
    "total_acc = total_correct / total\n",
    "print(\"\\n Overall test set accuracy (i.e. effectiveness of poison): %.2f%%\" % (total_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02d1671-a354-43c1-bb38-182e94d45db4",
   "metadata": {},
   "source": [
    "### Filter Poison Using STRIP\n",
    "\n",
    "Same as Spectral Signatures procedure until model training and adversarial example generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8ccd9-13b9-44ad-9f18-b2654df40f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "strip = STRIP(classifier)\n",
    "defence = strip()\n",
    "defence.mitigate(clean_x_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e288b1e1-fa12-4943-9109-6fb6d9aa354d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstained 1314/5590 poison samples (23.51% TP rate)\n",
      "Abstained 83/9900 clean samples (0.84% FP rate)\n"
     ]
    }
   ],
   "source": [
    "poison_preds = defence.predict(poison_x_test)\n",
    "clean_preds = defence.predict(clean_x_test[100:])\n",
    "\n",
    "num_abstained_poison = np.sum(np.all(poison_preds == np.zeros(10),axis=1))\n",
    "num_abstained_clean = np.sum(np.all(clean_preds == np.zeros(10),axis=1))\n",
    "num_poison = len(poison_preds)\n",
    "num_clean = len(clean_preds)\n",
    "\n",
    "print(f\"Abstained {num_abstained_poison}/{num_poison} poison samples ({round(num_abstained_poison / float(num_poison)* 100, 2)}% TP rate)\")\n",
    "print(f\"Abstained {num_abstained_clean}/{num_clean} clean samples ({round(num_abstained_clean / float(num_clean) * 100, 2)}% FP rate)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e1cb3c-913e-4dae-894c-13eff42b463a",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 2. Neural Cleanse\n",
    "\n",
    "### API Reference:\n",
    "- https://adversarial-robustness-toolbox.readthedocs.io/en/latest/modules/defences/transformer_poisoning.html#neural-cleanse\n",
    "\n",
    "### Related paper:\n",
    "- https://people.cs.uchicago.edu/~ravenben/publications/pdf/backdoor-sp19.pdf\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc9549-89bd-4c60-ba2c-42fcd0bc8c2a",
   "metadata": {},
   "source": [
    "### Build and train model with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e7db4c-207f-45c2-82d9-02f03ebdf553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Keras convolutional neural network - basic architecture from Keras examples\n",
    "# Source here: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777e416-27ff-4831-ba69-ed83054fd3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11640 samples\n",
      "Epoch 1/3\n",
      "11640/11640 [==============================] - 1s 81us/sample - loss: 0.6851 - accuracy: 0.7752\n",
      "Epoch 2/3\n",
      "11640/11640 [==============================] - 1s 76us/sample - loss: 0.1740 - accuracy: 0.9491\n",
      "Epoch 3/3\n",
      "11640/11640 [==============================] - 1s 75us/sample - loss: 0.1147 - accuracy: 0.9669\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(model=model, clip_values=(min_, max_))\n",
    "classifier.fit(x_train, y_train, nb_epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1911a7-454b-474d-be26-608cef614ea9",
   "metadata": {},
   "source": [
    "### Evaluate the model with poisoning sample (Backdoor attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd96d3d-4562-496b-bc0a-8ec26cdf6c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1\n",
      "\n",
      " Effectiveness of poison: 100.00%\n"
     ]
    }
   ],
   "source": [
    "poison_x_test = x_test[is_poison_test]\n",
    "poison_y_test = y_test[is_poison_test]\n",
    "\n",
    "poison_preds = np.argmax(classifier.predict(poison_x_test), axis=1)\n",
    "poison_correct = np.sum(poison_preds == np.argmax(poison_y_test, axis=1))\n",
    "poison_total = poison_y_test.shape[0]\n",
    "\n",
    "# Display image, label, and prediction for a poisoned image to see the backdoor working\n",
    "\n",
    "c = 1 # class to display\n",
    "i = 0 # image of the class to display\n",
    "\n",
    "c_idx = np.where(np.argmax(poison_y_test,1) == c)[0][i] # index of the image in poison arrays\n",
    "\n",
    "plt.imshow(poison_x_test[c_idx].squeeze())\n",
    "plt.show()\n",
    "poison_label = c\n",
    "print(\"Prediction: \" + str(poison_preds[c_idx]))\n",
    "\n",
    "poison_acc = poison_correct / poison_total\n",
    "print(\"\\n Effectiveness of poison: %.2f%%\" % (poison_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d88da-acfd-4b82-9563-136d0353e372",
   "metadata": {},
   "source": [
    "#### Evaluate accuracy on entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423632c-d526-41f5-a7a7-d4ecfb8babac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Overall test set accuracy: 97.98%\n"
     ]
    }
   ],
   "source": [
    "total_correct = clean_correct + poison_correct\n",
    "total = clean_total + poison_total\n",
    "\n",
    "total_acc = total_correct / total\n",
    "print(\"\\n Overall test set accuracy: %.2f%%\" % (total_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a722a1-3de1-4257-96b8-e97162837688",
   "metadata": {},
   "source": [
    "### Apply NeuralCleanse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ea0bf-25c5-427e-8d3d-38bb086006ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.defences.transformer.poisoning import NeuralCleanse\n",
    "\n",
    "cleanse = NeuralCleanse(classifier)\n",
    "defence_cleanse = cleanse(classifier, steps=10, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b623a-72b1-4f10-a462-3f8c2494ccdb",
   "metadata": {},
   "source": [
    "### Identifying the Backdoor\n",
    "\n",
    "Unlike most defenses, part of the procedure for this defense is identifying exactly what the suspected backdoor is for each class. \n",
    "Below is the _reverse-engineered backdoor_. This will be appended to clean images to mimic backdoor behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47a5c1d9-31e6-4f2a-b418-0fa6cfb7c0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2272700a62e42c4aa8da3970085d866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 1:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8d29532e90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pattern, mask = defence_cleanse.generate_backdoor(x_test, y_test, np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
    "plt.imshow(np.squeeze(mask * pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3581b996-709e-46c4-bd66-63dedced2229",
   "metadata": {},
   "source": [
    "Usually `generate_backdoor` is called as a result of calling `mitigate`. During this process, this defense **_generates a suspected backdoor for each class_**  visualized above. The `mitigate` method also performs the mitigation types presented below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8572be9-69ad-4519-9954-0e0cc2e4b48f",
   "metadata": {},
   "source": [
    "### Mitigation Types\n",
    "\n",
    "There are different mitigation methods that are described below.\n",
    "\n",
    "#### Filtering\n",
    "\n",
    "Filtering is the process of abstaining from potentially poisonous predictions at runtime. When this method is set, neurons are ranked by their association with the backdoor, and when neural activations are higher than normal, the classifier abstains from predication (output is all zeros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eea74de2-f28d-45a3-bd50-2eced2ebd5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a599452af084438cac5010cedd5854fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 0:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf0f8d026034f7288f8045f7aef488d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 1:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ef9d3cee904f96a97c6e61e99ba560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 2:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99affb39bd34691a7bf83c4f966f8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 3:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba54fdf9ca54beaa20ab850a70084a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 4:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a20d06571541e78fb01f2f2714b778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 5:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e780731e58400cabc1f7bb3f1074e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 6:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c696b41f89bc4e498f4aa50af9fd9156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 7:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce06fb286e834393b7320f767b175f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 8:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0581bb947a4fb2b4fac18e5eb07506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 9:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "defence_cleanse = cleanse(classifier, steps=10, learning_rate=0.1)\n",
    "defence_cleanse.mitigate(clean_x_test, clean_y_test, mitigation_types=[\"filtering\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31f64837-3172-478a-8dbc-26bb455a5bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 5176/5590 poison samples (92.59% effective)\n"
     ]
    }
   ],
   "source": [
    "poison_pred = defence_cleanse.predict(poison_x_test)\n",
    "num_filtered = np.sum(np.all(poison_pred == np.zeros(10), axis=1))\n",
    "num_poison = len(poison_pred)\n",
    "effectiveness = float(num_filtered) / num_poison * 100\n",
    "print(\"Filtered {}/{} poison samples ({:.2f}% effective)\".format(num_filtered, num_poison, effectiveness))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9566aa-690f-4b20-a88f-b9d80b0220bc",
   "metadata": {},
   "source": [
    "#### Unlearning\n",
    "\n",
    "Unlearning is the process of _retraining the backdoors with the correct label for one epoch_. This works best for Trojan-style triggers that react to a specific neuron configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef3cfa1f-98e6-4bef-889b-d4440174c9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055e667adae14dd2a3dc55a3e394c59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 0:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f720b118865d40eaa9a13fcb8e012984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 1:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e093dbdf26c45eea1a118b97082fe95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 2:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9622d974a060400da72805c31678ee68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 3:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637247c700764ae98f342215ac55c43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 4:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7428d2fa955a467fad899b840a6dab93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 5:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83dc370c76f64635b0b21404ff3d5d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 6:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825fe1d5c38d4026851e06bfc2d78bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 7:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194a17571b5a4e2b97a3e0eff499ab07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 8:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7da4faa588d4373b200ffd9ffeeb11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 9:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3147 samples\n",
      "3147/3147 [==============================] - 11s 4ms/sample - loss: 0.0125 - accuracy: 0.9981\n"
     ]
    }
   ],
   "source": [
    "defence_cleanse = cleanse(classifier, steps=10, learning_rate=0.1)\n",
    "defence_cleanse.mitigate(clean_x_test, clean_y_test, mitigation_types=[\"unlearning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ec512c7-148b-4d16-bdad-814e86b772c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Effectiveness of poison after unlearning: 91.95% (previously 100.00%)\n",
      "\n",
      " Clean test set accuracy: 29.64% (previously 96.85%)\n"
     ]
    }
   ],
   "source": [
    "poison_preds = np.argmax(classifier.predict(poison_x_test), axis=1)\n",
    "poison_correct = np.sum(poison_preds == np.argmax(poison_y_test, axis=1))\n",
    "poison_total = poison_y_test.shape[0]\n",
    "new_poison_acc = poison_correct / poison_total\n",
    "print(\"\\n Effectiveness of poison after unlearning: %.2f%% (previously %.2f%%)\" % (new_poison_acc * 100, poison_acc * 100))\n",
    "clean_preds = np.argmax(classifier.predict(clean_x_test), axis=1)\n",
    "clean_correct = np.sum(clean_preds == np.argmax(clean_y_test, axis=1))\n",
    "clean_total = clean_y_test.shape[0]\n",
    "\n",
    "new_clean_acc = clean_correct / clean_total\n",
    "print(\"\\n Clean test set accuracy: %.2f%% (previously %.2f%%)\" % (new_clean_acc * 100, clean_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55c32c-e825-448f-a0b3-8815adf04be1",
   "metadata": {},
   "source": [
    "#### Pruning\n",
    "\n",
    "Pruning is the process of _zero-ing out neurons strongly associated with backdoor behavior_ until the backdoor is ineffective or 30% of all neurons have been pruned. Be careful as this can negatively affect the accuracy of your model. This works best for fully mitigating the effects of backdoor poisoning attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18f05d40-bdcb-43c1-a0ac-3ff43933cb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12be079fdc914ef78472073d5479a919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 0:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbf1b25f608410d98123a90b56d6624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 1:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325259d446334ef1bb70ec478c8d072f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 2:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6dce16c0d642cbb473dcee2849fc16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 3:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a87a9586164e17b2c455bec515787f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 4:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88bf29779554f88a7dad0421587240e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 5:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7c92f3441248a59502e6d716d347af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 6:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f6bf54002c4421a4382036a991cdb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 7:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6580f5aa39804664af16511b7e145ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 8:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c789af3fe34195b52d8169869d66b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 9:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "defence_cleanse = cleanse(classifier, steps=10, learning_rate=0.1)\n",
    "defence_cleanse.mitigate(clean_x_test, clean_y_test, mitigation_types=[\"pruning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11b3f574-3672-47ab-b6bf-7bf2bd02fe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Effectiveness of poison after pruning: 91.95% (previously 100.00%)\n",
      "\n",
      " Clean test set accuracy: 29.64% (previously 96.85%)\n"
     ]
    }
   ],
   "source": [
    "poison_preds = np.argmax(classifier.predict(poison_x_test), axis=1)\n",
    "poison_correct = np.sum(poison_preds == np.argmax(poison_y_test, axis=1))\n",
    "poison_total = poison_y_test.shape[0]\n",
    "new_poison_acc = poison_correct / poison_total\n",
    "print(\"\\n Effectiveness of poison after pruning: %.2f%% (previously %.2f%%)\" % (new_poison_acc * 100, poison_acc * 100))\n",
    "clean_preds = np.argmax(classifier.predict(clean_x_test), axis=1)\n",
    "clean_correct = np.sum(clean_preds == np.argmax(clean_y_test, axis=1))\n",
    "clean_total = clean_y_test.shape[0]\n",
    "\n",
    "new_clean_acc = clean_correct / clean_total\n",
    "print(\"\\n Clean test set accuracy: %.2f%% (previously %.2f%%)\" % (new_clean_acc * 100, clean_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8589e-1ada-49cb-a404-5e3f320465cd",
   "metadata": {},
   "source": [
    "#### Combination\n",
    "\n",
    "Finally, you can also do a combination of any of the above mitigation methods to fit your needs. Just add those types to the `mitigation_types` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22434300-cb44-4efe-a4c1-c8834366d586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59743f70ea0a4afeb18c4d8e1c4e57e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 0:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab3e12491a441d798bb5977e1b9971b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 1:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad17274662c4048a6de26a3de4ea0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 2:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee41c05498b24fefafcc2bb3e3de4d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 3:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1a5f15bec8402fbaafc81778a043ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 4:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5305935ba184a8a957af8da4cacada2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 5:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46fbaa62b4a48f5a9eb8349cc6fa80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 6:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cb7219daaa4d398124005aa6c7aa99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 7:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd2d48e01f44485acf0216f00390d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 8:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32c2982501e4f328dc0392d0f989e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating backdoor for class 9:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "defence_cleanse.mitigate(clean_x_test, clean_y_test, mitigation_types=[\"pruning\", \"filtering\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57508edb-94df-44d4-892f-9452d8d57ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Effectiveness of poison after pruning: 91.95% (previously 100.00%)\n",
      "\n",
      " Clean test set accuracy: 29.64% (previously 96.85%)\n"
     ]
    }
   ],
   "source": [
    "poison_preds = np.argmax(classifier.predict(poison_x_test), axis=1)\n",
    "poison_correct = np.sum(poison_preds == np.argmax(poison_y_test, axis=1))\n",
    "poison_total = poison_y_test.shape[0]\n",
    "new_poison_acc = poison_correct / poison_total\n",
    "print(\"\\n Effectiveness of poison after pruning: %.2f%% (previously %.2f%%)\" % (new_poison_acc * 100, poison_acc * 100))\n",
    "clean_preds = np.argmax(classifier.predict(clean_x_test), axis=1)\n",
    "clean_correct = np.sum(clean_preds == np.argmax(clean_y_test, axis=1))\n",
    "clean_total = clean_y_test.shape[0]\n",
    "\n",
    "new_clean_acc = clean_correct / clean_total\n",
    "print(\"\\n Clean test set accuracy: %.2f%% (previously %.2f%%)\" % (new_clean_acc * 100, clean_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
